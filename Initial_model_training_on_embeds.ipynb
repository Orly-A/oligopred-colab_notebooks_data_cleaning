{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Initial_model_training_on_embeds.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"VNJrFeWILjmv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657700207502,"user_tz":-180,"elapsed":21190,"user":{"displayName":"Orly Avraham","userId":"04776896467723204969"}},"outputId":"95eb8167-182d-43f0-d7d2-75409cb285cc"},"source":["import re\n","import os\n","import pickle \n","import numpy as np \n","import pandas as pd\n","import sys\n","from sklearn.model_selection import train_test_split\n","from sklearn import metrics\n","from sklearn.model_selection import StratifiedGroupKFold \n","import xgboost as xgb\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import f1_score\n","\n","\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# load the tab used for embedding, only the training set of course\n","\n","with open(\"drive/MyDrive/OrlyPred/Homomer_embeds/results/embeds_Mar_22/train_set.pkl\", 'rb') as f:\n","  overall_train_set = pickle.load(f)\n","\n","# index reset is important for the stratified splitting and the saving to lists\n","overall_train_set.reset_index(drop=True, inplace=True)"],"metadata":{"id":"J6m3KfNJcMSA","executionInfo":{"status":"ok","timestamp":1657700211115,"user_tz":-180,"elapsed":3617,"user":{"displayName":"Orly Avraham","userId":"04776896467723204969"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# define the input, using the codes since this is convenient to later extract rows from the general table. Actually the input is the embeddings\n","# the labls, y, are the predifined nsub (number of subunits annotated to the relevant pdb code)\n","# groups - the cluster representatives, used in order to jave all the sequences from the same cluster in the same set (train/validation)\n","\n","X = overall_train_set[\"code\"]\n","y = overall_train_set[\"nsub\"]\n","groups = overall_train_set[\"representative\"]\n","X"],"metadata":{"id":"oeX-ovjDc6xO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657700211117,"user_tz":-180,"elapsed":7,"user":{"displayName":"Orly Avraham","userId":"04776896467723204969"}},"outputId":"fb01d09d-df0f-4440-e691-010a88d078a1"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0        5ahz_1\n","1        3q6m_1\n","2        1luq_1\n","3        3t6f_1\n","4        1srf_1\n","          ...  \n","28823    4zt1_1\n","28824    4a56_1\n","28825    5hap_1\n","28826    4s2l_1\n","28827    5faq_1\n","Name: code, Length: 28828, dtype: object"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["# generate groups for k-fold cross validation, used in the next few cells\n","# this is used when one run is carried out, for the cross validation there is a different code below \n","\n","cv = StratifiedGroupKFold(n_splits=10, shuffle=True, random_state=1)\n","train_lst = []\n","test_lst = []\n","for train_idxs, test_idxs in cv.split(X, y, groups):\n","    train_lst.append(X[train_idxs].tolist())\n","    test_lst.append(X[test_idxs].tolist())\n","    print(\"train_lst\", train_lst)\n","    print(\"test_lst\", test_lst)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t62vA1M7cdH3","executionInfo":{"status":"ok","timestamp":1657700231768,"user_tz":-180,"elapsed":20656,"user":{"displayName":"Orly Avraham","userId":"04776896467723204969"}},"outputId":"0a35f0c7-20a6-4042-ccda-cb4cce925bc3"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:880: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n","  UserWarning,\n","IOPub data rate exceeded.\n","The notebook server will temporarily stop sending output\n","to the client in order to avoid crashing it.\n","To change this limit, set the config variable\n","`--NotebookApp.iopub_data_rate_limit`.\n","\n","Current values:\n","NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n","NotebookApp.rate_limit_window=3.0 (secs)\n","\n"]}]},{"cell_type":"code","source":["train_lst[0]"],"metadata":{"id":"VUx3rSDyc52m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_idx_df = pd.DataFrame(train_lst).transpose()\n","train_idx_df.rename(columns={0:\"train_0\", 1:\"train_1\", 2:\"train_2\", 3:\"train_3\", 4:\"train_4\", 5:\"train_5\", 6:\"train_6\", 7:\"train_7\", 8:\"train_8\", 9:\"train_9\"}, inplace=True)\n","print(train_idx_df)\n","test_idx_df = pd.DataFrame(test_lst).transpose()\n","test_idx_df.rename(columns={0:\"test_0\", 1:\"test_1\", 2:\"test_2\", 3:\"test_3\", 4:\"test_4\", 5:\"test_5\", 6:\"test_6\", 7:\"test_7\", 8:\"test_8\", 9:\"test_9\"}, inplace=True)\n","print(test_idx_df)\n","merged_train_test = pd.concat([train_idx_df, test_idx_df], axis=1, join=\"outer\")\n"],"metadata":{"id":"sc95sfwfc5Kn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#For 5-fold cv\n","train_idx_df = pd.DataFrame(train_lst).transpose()\n","train_idx_df.rename(columns={0:\"train_0\", 1:\"train_1\", 2:\"train_2\", 3:\"train_3\", 4:\"train_4\"}, inplace=True)\n","print(train_idx_df)\n","test_idx_df = pd.DataFrame(test_lst).transpose()\n","test_idx_df.rename(columns={0:\"test_0\", 1:\"test_1\", 2:\"test_2\", 3:\"test_3\", 4:\"test_4\"}, inplace=True)\n","print(test_idx_df)\n","merged_train_test = pd.concat([train_idx_df, test_idx_df], axis=1, join=\"outer\")\n"],"metadata":{"id":"0dFRuarlojfw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_set = overall_train_set[overall_train_set[\"code\"].isin(merged_train_test[\"train_0\"])]\n","test_set = overall_train_set[overall_train_set[\"code\"].isin(merged_train_test[\"test_0\"])]"],"metadata":{"id":"iNeQgCbl09bW","executionInfo":{"status":"ok","timestamp":1657700269333,"user_tz":-180,"elapsed":277,"user":{"displayName":"Orly Avraham","userId":"04776896467723204969"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"IzawLNJxGs5F"},"source":["from sklearn.neural_network import MLPClassifier\n","\n","X_train = train_set['embeddings'].tolist()\n","y_train = train_set['nsub']\n","\n","X_test = test_set['embeddings'].tolist()\n","y_test = test_set['nsub']\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZCyIW3_7IDVM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652959568643,"user_tz":-180,"elapsed":295933,"user":{"displayName":"Orly Avraham","userId":"04776896467723204969"}},"outputId":"68f1013c-c917-4773-fbd5-cc4c68be47bd"},"source":[" # the basic plain vanilla MLP trained on one fold, for a baseline/initial model\n","clf = MLPClassifier(solver='adam', random_state=1, learning_rate_init=0.001)\n","clf.fit(X_train, y_train)\n","y_pred = clf.predict(X_test)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  ConvergenceWarning,\n"]}]},{"cell_type":"code","metadata":{"id":"xYWotdnBIJWc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652959568644,"user_tz":-180,"elapsed":7,"user":{"displayName":"Orly Avraham","userId":"04776896467723204969"}},"outputId":"113e35e9-b35f-4755-fbec-a0ff28040514"},"source":["print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n","print(\"adjusted Balanced accuracy:\", metrics.balanced_accuracy_score(y_test, y_pred, adjusted=True))\n","# print(\"roc_auc_score:\", metrics.roc_auc_score(y_test, y_pred, multi_class='ovr'))\n","# print(\"PR:\", metrics.precision_recall_fscore_support(y_test,y_pred))\n","print('Precision: %.3f' % precision_score(y_test, y_pred, average='weighted'))\n","print('Recall: %.3f' % recall_score(y_test, y_pred, average='weighted'))\n","print('F-measure: %.3f' % f1_score(y_test, y_pred, average='weighted'))\n","print(metrics.classification_report(y_test,y_pred))\n","print(metrics.confusion_matrix(y_test,y_pred))\n","\n","\n","\n","import matplotlib.pyplot as plt \n","\n","# metrics.plot_roc_curve(clf, X_test, y_test)  \n","# plt.show()                                   \n","\n","# metrics.RocCurveDisplay.from_predictions(clf, X_test, y_test)\n","# plt.show()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.6069635085369937\n","adjusted Balanced accuracy: 0.3066657481475936\n","Precision: 0.624\n","Recall: 0.607\n","F-measure: 0.609\n","              precision    recall  f1-score   support\n","\n","         1.0       0.76      0.68      0.72      1582\n","         2.0       0.47      0.60      0.53       935\n","         3.0       0.50      0.48      0.49        93\n","         4.0       0.47      0.46      0.46       213\n","         5.0       1.00      1.00      1.00         2\n","         6.0       0.41      0.25      0.31        75\n","         8.0       0.27      0.11      0.16        27\n","        10.0       0.64      0.18      0.29        38\n","        12.0       0.36      0.36      0.36        14\n","        13.0       0.00      0.00      0.00         1\n","        14.0       1.00      0.25      0.40         4\n","        24.0       0.00      0.00      0.00         3\n","\n","    accuracy                           0.61      2987\n","   macro avg       0.49      0.36      0.39      2987\n","weighted avg       0.62      0.61      0.61      2987\n","\n","[[1073  475   17   12    0    3    2    0    0    0    0    0]\n"," [ 281  561   14   65    0   11    3    0    0    0    0    0]\n"," [  19   17   45    4    0    7    0    1    0    0    0    0]\n"," [  12   83    7   97    0    4    3    1    6    0    0    0]\n"," [   0    0    0    0    2    0    0    0    0    0    0    0]\n"," [  16   16    3   18    0   19    0    0    3    0    0    0]\n"," [   4   13    0    7    0    0    3    0    0    0    0    0]\n"," [   2   25    1    2    0    1    0    7    0    0    0    0]\n"," [   0    3    3    1    0    0    0    2    5    0    0    0]\n"," [   1    0    0    0    0    0    0    0    0    0    0    0]\n"," [   0    2    0    0    0    1    0    0    0    0    1    0]\n"," [   0    3    0    0    0    0    0    0    0    0    0    0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","source":["# use the DummyClassifier to examine the quality of the model\n","from sklearn.dummy import DummyClassifier\n","\n","clf_dum = DummyClassifier(strategy='most_frequent', random_state=1)\n","clf_dum.fit(X_train, y_train)\n","\n","y_pred = clf_dum.predict(X_test)\n","print(\"DummyClassifier Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n","print(\"DummyClassifier adjusted Balanced accuracy:\", metrics.balanced_accuracy_score(y_test, y_pred, adjusted=True))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fEEPmObP5Dqw","executionInfo":{"status":"ok","timestamp":1652945424235,"user_tz":-180,"elapsed":422,"user":{"displayName":"Orly Avraham","userId":"04776896467723204969"}},"outputId":"85de0db7-d0e4-4bd7-9efd-f9f40d0c1c62"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["DummyClassifier Accuracy: 0.5296283896886508\n","DummyClassifier adjusted Balanced accuracy: 0.0\n"]}]},{"cell_type":"code","source":["# use the DummyClassifier to examine the quality of the model, here with a different strategy for generating the dummy classifier\n","from sklearn.dummy import DummyClassifier\n","\n","clf_dum2 = DummyClassifier(strategy='stratified', random_state=1)\n","clf_dum2.fit(X_train, y_train)\n","\n","y_pred = clf_dum2.predict(X_test)\n","print(\"DummyClassifier Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n","print(\"DummyClassifier adjusted Balanced accuracy:\", metrics.balanced_accuracy_score(y_test, y_pred, adjusted=True))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F3SDd9QQ-ntd","executionInfo":{"status":"ok","timestamp":1652945430015,"user_tz":-180,"elapsed":409,"user":{"displayName":"Orly Avraham","userId":"04776896467723204969"}},"outputId":"b22417c9-e928-4d96-b773-f9147e97171e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["DummyClassifier Accuracy: 0.3592233009708738\n","DummyClassifier adjusted Balanced accuracy: -0.009255158786592813\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1987: UserWarning: y_pred contains classes not in y_true\n","  warnings.warn(\"y_pred contains classes not in y_true\")\n"]}]},{"cell_type":"code","source":["# train an MLP with k-fold cross valdation (k=10)\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.model_selection import cross_val_score\n","\n","\n","\n","X = overall_train_set[\"embeddings\"]\n","y = overall_train_set[\"nsub\"]\n","groups = overall_train_set[\"representative\"]\n","cv = StratifiedGroupKFold(n_splits=10)\n","\n","\n","\n","clf = MLPClassifier(solver='adam', random_state=1, learning_rate_init=0.001)\n","\n","\n","for train_idxs, test_idxs in cv.split(X, y, groups):\n","    clf.fit(np.vstack(X[train_idxs]), y[train_idxs])\n","    print(clf.score(np.vstack(X[test_idxs]), y[test_idxs]))\n","    clf.fit(np.vstack(X[train_idxs]), y[train_idxs])\n","    y_pred = clf.predict(np.vstack(X[test_idxs]))\n","    print(\"Adjusted Balanced accuracy:\", metrics.balanced_accuracy_score(y[test_idxs], y_pred, adjusted=True))\n","    print(\"Balanced accuracy:\", metrics.balanced_accuracy_score(y[test_idxs], y_pred))\n","    print('F-measure: %.3f' % f1_score(y[test_idxs], y_pred, average='weighted'))\n","\n","    # scores = cross_val_score(clf, X, y, cv=cv)\n","\n","    # print(\"TRAIN:\", X[train_idxs])\n","    # print(\"      \", y[train_idxs])\n","    # print(\" TEST:\", X[test_idxs])\n","    # print(\"      \", y[test_idxs])\n","\n"],"metadata":{"id":"qDh_4qGfHAW2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2g8SLlwP7adO"},"source":["*Decision tree*\n","xgboost\n"]},{"cell_type":"code","source":["# original cell\n","\n","X = overall_train_set[\"embeddings\"]\n","y = overall_train_set[\"nsub\"]\n","groups = overall_train_set[\"representative\"]\n","cv = StratifiedGroupKFold(n_splits=10)\n","\n","X_train = pd.DataFrame(np.vstack(train_set['embeddings']))\n","y_train = train_set['nsub']\n","\n","X_test = pd.DataFrame(np.vstack(test_set['embeddings']))\n","y_test = test_set['nsub']\n","\n","\n","\n","\n","df = pd.DataFrame(np.vstack(X))\n"],"metadata":{"id":"67Yh-C-o2lqx","executionInfo":{"status":"ok","timestamp":1657702170591,"user_tz":-180,"elapsed":701,"user":{"displayName":"Orly Avraham","userId":"04776896467723204969"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["#for understanding how to work with the model\n","\n","X = overall_train_set[\"embeddings\"][:1000]\n","y = overall_train_set[\"nsub\"][:1000]\n","groups = overall_train_set[\"representative\"][:1000]\n","cv = StratifiedGroupKFold(n_splits=1000)\n","\n","X_train = pd.DataFrame(np.vstack(train_set['embeddings'][:1000]))\n","y_train = train_set['nsub'][:1000]\n","\n","X_test = pd.DataFrame(np.vstack(test_set['embeddings'][:1000]))\n","y_test = test_set['nsub'][:1000]\n","\n","\n","\n","\n","df = pd.DataFrame(np.vstack(X))\n"],"metadata":{"id":"_hytLxh6E34K","executionInfo":{"status":"ok","timestamp":1657701189709,"user_tz":-180,"elapsed":589,"user":{"displayName":"Orly Avraham","userId":"04776896467723204969"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":[" data_dmatrix = xgb.DMatrix(data=df,label=y)"],"metadata":{"id":"TLQ-2gti95_l","executionInfo":{"status":"ok","timestamp":1657702177963,"user_tz":-180,"elapsed":885,"user":{"displayName":"Orly Avraham","userId":"04776896467723204969"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# train model from params after HPT July 2022\n","best_params = {'eta': 0.4,\n"," 'max_depth': 6,\n"," 'min_child_weight': 9,\n"," 'n_estimators': 1500,\n"," 'objective': 'multi:softprob',\n"," 'tree_method': 'approx'}\n","\n","\n","xg_class = xgb.XGBClassifier(objective ='multi:softprob', eta=0.4, max_depth=6, min_child_weight=9, n_estimators=1500, tree_method=\"approx\")\n","\n","xg_class.fit(X_train,y_train)\n","\n","pickle.dump(xg_class, open(\"drive/MyDrive/OrlyPred/Homomer_embeds/results/embeds_Mar_22/xgb_model.pkl\", \"wb\"))\n","joblib.dump(xg_class, \"drive/MyDrive/OrlyPred/Homomer_embeds/results/embeds_Mar_22/xgb_random.joblib\")\n","\n","\n","preds = xg_class.predict(X_test)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":409},"id":"qr__w-Y9pFjU","executionInfo":{"status":"error","timestamp":1657710343529,"user_tz":-180,"elapsed":8151494,"user":{"displayName":"Orly Avraham","userId":"04776896467723204969"}},"outputId":"3974596e-4d3e-47c3-fa02-2495fec3501d"},"execution_count":14,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-42dd81cb7b02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mxg_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'multi:softprob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_child_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"approx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mxg_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"drive/MyDrive/OrlyPred/Homomer_embeds/results/embeds_Mar_22/xgb_model.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    730\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# flow (and params) from here: https://www.datacamp.com/community/tutorials/xgboost-in-python\n","\n","xg_class = xgb.XGBClassifier(objective ='reg:logistic', colsample_bytree = 0.3, learning_rate = 0.1,\n","                max_depth = 5, alpha = 10, n_estimators = 10, random_state=1)\n","\n","xg_class.fit(X_train,y_train)\n","\n","preds = xg_class.predict(X_test)\n","\n"],"metadata":{"id":"m321YsxB2mdM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rmse = np.sqrt(mean_squared_error(y_test, preds))\n","print(\"RMSE: %f\" % (rmse))\n","print('Accuracy: %.3f' % accuracy_score(y_test, preds))\n","print('Precision: %.3f' % precision_score(y_test, preds, average='weighted'))\n","print('Recall: %.3f' % recall_score(y_test, preds, average='weighted'))\n","print('F-measure: %.3f' % f1_score(y_test, preds, average='weighted'))\n","print(\"adjusted Balanced accuracy:\", metrics.balanced_accuracy_score(y_test, y_pred, adjusted=True))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gCW5-hu13Hr-","executionInfo":{"status":"ok","timestamp":1652883880873,"user_tz":-180,"elapsed":430,"user":{"displayName":"Orly Avraham","userId":"04776896467723204969"}},"outputId":"987387ca-bb3d-43bc-8e78-ecdd8cb2f9b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["RMSE: 1.852170\n","Accuracy: 0.608\n","Precision: 0.591\n","Recall: 0.608\n","F-measure: 0.570\n","adjusted Balanced accuracy: 0.046639279667793895\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"4X15ZTBVLaxS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["####### Doesnt work yet\n","# fit xgboost on an imbalanced classification dataset\n","\n","from sklearn.datasets import make_classification\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import RepeatedStratifiedKFold\n","from sklearn.metrics import roc_auc_score, make_scorer\n","from xgboost import XGBClassifier\n","# generate dataset\n","\n","X = pd.DataFrame(np.vstack(overall_train_set['embeddings']))\n","cv = StratifiedGroupKFold(n_splits=10)\n","# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n","\n","\n","xgb_model = xgb.XGBClassifier(objective ='reg:logistic', cv=cv, groups=groups, random_state=1)\n","# xgb_model.fit(X, y)\n","\n","# y_pred = xgb_model.predict(X)\n","\n","\n","\n","\n","f1_score_weighted = make_scorer(f1_score, average=\"weighted\")\n","f1_score_weighted\n","\n","# scores = cross_val_score(xgb_model, scoring=roc_auc_ovr_scorer, n_jobs=-1, error_score='raise')\n","# # original line:\n","scores = cross_val_score(xgb_model, X, y, cv=cv, n_jobs=-1, scoring=f1_score_weighted, error_score='raise', groups=groups) #, scoring=roc_auc_ovr_scorer #scoring='roc_auc_ovr', \n","# print(y_true)\n","# print(y_score)\n","\n","print('f1_score_weighted: %.5f' % np.mean(scores))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CGv7UHuY3ICs","executionInfo":{"status":"ok","timestamp":1652987137355,"user_tz":-180,"elapsed":21479321,"user":{"displayName":"Orly Avraham","userId":"04776896467723204969"}},"outputId":"9d569d11-0d3f-4b1d-cd25-3a8076196b5a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:880: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n","  UserWarning,\n"]},{"output_type":"stream","name":"stdout","text":["f1_score_weighted: 0.56044\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"15CXUH-a3IZ9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"7-gJCzQ_3Ika"},"execution_count":null,"outputs":[]}]}