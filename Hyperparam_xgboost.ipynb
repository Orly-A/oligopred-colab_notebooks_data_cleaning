{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Hyperparam_xgboost.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP7udeXtwWThKEQeJwQbhwI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"UZMg6mp0WKZz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653996798959,"user_tz":-180,"elapsed":20156,"user":{"displayName":"Orly Avraham","userId":"04776896467723204969"}},"outputId":"08078bad-133b-4961-f193-28cbc9d1a7f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import re\n","import os\n","import pickle \n","import numpy as np \n","import pandas as pd\n","import sys\n","import matplotlib.pyplot as plt \n","\n","from sklearn import metrics\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import StratifiedGroupKFold \n","from sklearn.model_selection import cross_val_score\n","\n","from sklearn.metrics import roc_auc_score, make_scorer\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import f1_score\n","from sklearn.dummy import DummyClassifier\n","\n","import xgboost as xgb\n","from xgboost import XGBClassifier\n","\n","\n","\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n"]},{"cell_type":"code","source":["# load the tab used for embedding, only the training set of course\n","\n","with open(\"drive/MyDrive/OrlyPred/Homomer_embeds/results/embeds_Mar_22/train_set.pkl\", 'rb') as f:\n","  overall_train_set = pickle.load(f)\n","\n","# index reset is important for the stratified splitting and the saving to lists\n","overall_train_set.reset_index(drop=True, inplace=True)"],"metadata":{"id":"GtB20VyxTWhd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# define the input, using the codes since this is convenient to later extract rows from the general table. Actually the input is the embeddings\n","# the labls, y, are the predifined nsub (number of subunits annotated to the relevant pdb code)\n","# groups - the cluster representatives, used in order to jave all the sequences from the same cluster in the same set (train/validation)\n","\n","X = overall_train_set[\"code\"]\n","y = overall_train_set[\"nsub\"]\n","groups = overall_train_set[\"representative\"]\n"],"metadata":{"id":"88ONLU8uTWqS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# generate groups for k-fold cross validation, used in the next few cells\n","# this is used when one run is carried out, for the cross validation there is a different code below \n","\n","cv = StratifiedGroupKFold(n_splits=10, shuffle=True, random_state=1)\n","train_lst = []\n","test_lst = []\n","for train_idxs, test_idxs in cv.split(X, y, groups):\n","    train_lst.append(X[train_idxs].tolist())\n","    test_lst.append(X[test_idxs].tolist())\n","    # print(\"train_lst\", train_lst)\n","    # print(\"test_lst\", test_lst)"],"metadata":{"id":"RxNfmJ8lTeu7","colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1xk0Vqqwt7_MuAxHX7Wu03F18u3FbV0PW"},"executionInfo":{"status":"ok","timestamp":1653570875233,"user_tz":-180,"elapsed":702,"user":{"displayName":"Orly Avraham","userId":"04776896467723204969"}},"outputId":"012bd2ae-e79a-4f47-bcc6-a0f2cecfb032"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["train_idx_df = pd.DataFrame(train_lst).transpose()\n","train_idx_df.rename(columns={0:\"train_0\", 1:\"train_1\", 2:\"train_2\", 3:\"train_3\", 4:\"train_4\", 5:\"train_5\", 6:\"train_6\", 7:\"train_7\", 8:\"train_8\", 9:\"train_9\"}, inplace=True)\n","# print(train_idx_df)\n","test_idx_df = pd.DataFrame(test_lst).transpose()\n","test_idx_df.rename(columns={0:\"test_0\", 1:\"test_1\", 2:\"test_2\", 3:\"test_3\", 4:\"test_4\", 5:\"test_5\", 6:\"test_6\", 7:\"test_7\", 8:\"test_8\", 9:\"test_9\"}, inplace=True)\n","# print(test_idx_df)\n","merged_train_test = pd.concat([train_idx_df, test_idx_df], axis=1, join=\"outer\")\n"],"metadata":{"id":"sc95sfwfc5Kn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_set = overall_train_set[overall_train_set[\"code\"].isin(merged_train_test[\"train_0\"])]\n","test_set = overall_train_set[overall_train_set[\"code\"].isin(merged_train_test[\"test_0\"])]"],"metadata":{"id":"iNeQgCbl09bW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2g8SLlwP7adO"},"source":["*Decision tree*\n","xgboost\n"]},{"cell_type":"code","source":["# original cell\n","\n","X = overall_train_set[\"embeddings\"]\n","y = overall_train_set[\"nsub\"]\n","groups = overall_train_set[\"representative\"]\n","cv = StratifiedGroupKFold(n_splits=10)\n","\n","# X_train = pd.DataFrame(np.vstack(train_set['embeddings']))\n","# y_train = train_set['nsub']\n","\n","# X_test = pd.DataFrame(np.vstack(test_set['embeddings']))\n","# y_test = test_set['nsub']\n","\n","\n","X = pd.DataFrame(np.vstack(overall_train_set['embeddings']))\n","\n","\n","df = pd.DataFrame(np.vstack(X))\n"],"metadata":{"id":"67Yh-C-o2lqx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#for understanding how to work with the model\n","\n","X = overall_train_set[\"embeddings\"][:1000]\n","y = overall_train_set[\"nsub\"][:1000]\n","groups = overall_train_set[\"representative\"][:1000]\n","cv = StratifiedGroupKFold(n_splits=1000)\n","\n","X_train = pd.DataFrame(np.vstack(train_set['embeddings'][:1000]))\n","y_train = train_set['nsub'][:1000]\n","\n","X_test = pd.DataFrame(np.vstack(test_set['embeddings'][:1000]))\n","y_test = test_set['nsub'][:1000]\n","\n","\n","X = pd.DataFrame(np.vstack(overall_train_set['embeddings'][:1000]))\n","\n","\n","df = pd.DataFrame(np.vstack(X))\n"],"metadata":{"id":"_hytLxh6E34K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y.astype(int)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oSPJOV8K5XpR","executionInfo":{"status":"ok","timestamp":1653996942436,"user_tz":-180,"elapsed":3,"user":{"displayName":"Orly Avraham","userId":"04776896467723204969"}},"outputId":"04d35d82-2c14-45d3-ec22-10284c6d2a22"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0        3\n","1        6\n","2        4\n","3        4\n","4        4\n","        ..\n","28823    2\n","28824    2\n","28825    2\n","28826    2\n","28827    2\n","Name: nsub, Length: 28828, dtype: int64"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["data_dmatrix = xgb.DMatrix(data=df,label=y)"],"metadata":{"id":"TLQ-2gti95_l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# flow (and params) from here: https://www.datacamp.com/community/tutorials/xgboost-in-python\n","\n","xg_class = xgb.XGBClassifier(objective ='reg:logistic', colsample_bytree = 0.3, learning_rate = 0.1,\n","                max_depth = 5, alpha = 10, n_estimators = 10, random_state=1)\n","\n","xg_class.fit(X_train,y_train)\n","\n","preds = xg_class.predict(X_test)\n","\n","\n","# params = {\"objective\":\"reg:linear\",'colsample_bytree': 0.3,'learning_rate': 0.1,\n","#                 'max_depth': 5, 'alpha': 10}\n","\n","# cv_results = xgb.cv(dtrain=data_dmatrix, params=params, nfold=3,\n","                    # num_boost_round=50,early_stopping_rounds=10,metrics=\"rmse\", as_pandas=True, seed=123)\n","\n","\n","\n","# for train_idxs, test_idxs in cv.split(X, y, groups):\n","#    # data_dmatrix = xgb.DMatrix(data=np.vstack(X[train_idxs],label=y[train_idxs])\n","\n","#     clf.fit(np.vstack(X[train_idxs]), y[train_idxs])\n","#     y_pred = clf.predict(np.vstack(X[test_idxs]))\n","#     print(clf.score(np.vstack(X[test_idxs]), y[test_idxs]))\n","#     print(\"Adjusted Balanced accuracy:\", metrics.balanced_accuracy_score(y[test_idxs], y_pred, adjusted=True))\n","#     print(\"Balanced accuracy:\", metrics.balanced_accuracy_score(y[test_idxs], y_pred))\n"],"metadata":{"id":"m321YsxB2mdM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rmse = np.sqrt(mean_squared_error(y_test, preds))\n","print(\"RMSE: %f\" % (rmse))\n","# print('Accuracy: %.3f' % accuracy_score(y_test, preds))\n","print('Precision: %.3f' % precision_score(y_test, preds, average='weighted'))\n","print('Recall: %.3f' % recall_score(y_test, preds, average='weighted'))\n","print('F-measure: %.3f' % f1_score(y_test, preds, average='weighted'))\n","print(\"adjusted Balanced accuracy: %.3f\" % metrics.balanced_accuracy_score(y_test, preds, adjusted=True))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gCW5-hu13Hr-","executionInfo":{"status":"ok","timestamp":1652883880873,"user_tz":-180,"elapsed":430,"user":{"displayName":"Orly Avraham","userId":"04776896467723204969"}},"outputId":"987387ca-bb3d-43bc-8e78-ecdd8cb2f9b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["RMSE: 1.852170\n","Accuracy: 0.608\n","Precision: 0.591\n","Recall: 0.608\n","F-measure: 0.570\n","adjusted Balanced accuracy: 0.046639279667793895\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","source":["# Code from here: \n","# https://towardsdatascience.com/cross-validation-and-hyperparameter-tuning-how-to-optimise-your-machine-learning-model-13f005af9d7d\n","\n","# Number of trees to be used\n","xgb_n_estimators = [int(x) for x in np.linspace(200, 2000, 10)]\n","\n","# Maximum number of levels in tree\n","xgb_max_depth = [int(x) for x in np.linspace(2, 20, 10)]\n","\n","# Minimum number of instaces needed in each node\n","xgb_min_child_weight = [int(x) for x in np.linspace(1, 10, 10)]\n","\n","# Tree construction algorithm used in XGBoost\n","xgb_tree_method = ['auto', 'exact', 'approx', 'hist', 'gpu_hist']\n","\n","# Learning rate\n","xgb_eta = [x for x in np.linspace(0.1, 0.6, 6)]\n","xgb_eta = [round(x, 1) for x in xgb_eta]\n","\n","# Minimum loss reduction required to make further partition\n","xgb_gamma = [int(x) for x in np.linspace(0, 0.5, 6)]\n","\n","# Learning objective used\n","xgb_objective = ['reg:squarederror', 'reg:squaredlogerror']\n","\n","# Create the grid\n","xgb_grid = {'n_estimators': xgb_n_estimators,\n","            'max_depth': xgb_max_depth,\n","            'min_child_weight': xgb_min_child_weight,\n","            'tree_method': xgb_tree_method,\n","            'eta': xgb_eta,\n","            'gamma': xgb_gamma,\n","            'objective': xgb_objective}\n"],"metadata":{"id":"4X15ZTBVLaxS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Code from here: \n","# https://towardsdatascience.com/cross-validation-and-hyperparameter-tuning-how-to-optimise-your-machine-learning-model-13f005af9d7d\n","\n","\n","from xgboost import XGBClassifier\n","from sklearn.model_selection import RandomizedSearchCV\n","\n","xgb_base = XGBClassifier()\n","\n","# Create the random search Random Forest\n","xgb_random = RandomizedSearchCV(estimator = xgb_base, param_distributions = xgb_grid, \n","                                n_iter = 60, cv = 10, verbose = 2, \n","                                random_state = 1, n_jobs = -1)\n","\n","# Fit the random search model\n","xgb_random.fit(X, y)\n","\n","# Get the optimal parameters\n","xgb_random.best_params_\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SC6UC5eAkWfN","outputId":"38d3d5a5-e836-4f19-ef35-06baae198da3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 10 folds for each of 60 candidates, totalling 600 fits\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n","  UserWarning,\n"]}]},{"cell_type":"code","source":["print(xgb_random.best_params_)"],"metadata":{"id":"D5AdQSl7rZQ0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# k-fold croos val without tuning\n","# fit xgboost on an imbalanced classification dataset\n","\n","from sklearn.datasets import make_classification\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import RepeatedStratifiedKFold\n","from sklearn.metrics import roc_auc_score, make_scorer\n","from xgboost import XGBClassifier\n","# generate dataset\n","\n","cv = StratifiedGroupKFold(n_splits=10, random_state=1)\n","# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n","\n","\n","xgb_model = xgb.XGBClassifier(objective ='reg:logistic', cv=cv, groups=groups, random_state=1)\n","# xgb_model.fit(X, y)\n","\n","# y_pred = xgb_model.predict(X)\n","\n","\n","\n","\n","# X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n","# \tn_clusters_per_class=2, weights=[0.99], flip_y=0, random_state=7)\n","# define model\n","# model = XGBClassifier()\n","# define evaluation procedure\n","# evaluate model\n","\n","f1_score_weighted = make_scorer(f1_score, average=\"weighted\")\n","f1_score_weighted\n","\n","# scores = cross_val_score(xgb_model, scoring=roc_auc_ovr_scorer, n_jobs=-1, error_score='raise')\n","# # original line:\n","scores = cross_val_score(xgb_model, X, y, cv=cv, n_jobs=-1, scoring=f1_score_weighted, error_score='raise', groups=groups) \n","# summarize performance\n","# print(y_true)\n","# print(y_score)\n","print('f1_score_weighted: %.5f' % np.mean(scores))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CGv7UHuY3ICs","executionInfo":{"status":"ok","timestamp":1652987137355,"user_tz":-180,"elapsed":21479321,"user":{"displayName":"Orly Avraham","userId":"04776896467723204969"}},"outputId":"9d569d11-0d3f-4b1d-cd25-3a8076196b5a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:880: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n","  UserWarning,\n"]},{"output_type":"stream","name":"stdout","text":["f1_score_weighted: 0.56044\n"]}]},{"cell_type":"code","source":["# scores = cross_val_score(xgb_model, X, y, scoring=roc_auc_ovr_scorer, cv=cv, n_jobs=-1, error_score='raise', groups=groups)\n"],"metadata":{"id":"14K6W-_d1kDP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cv = StratifiedGroupKFold(n_splits=10, shuffle=True, random_state=1, )\n","lst_accu_stratified = []\n","  \n","for train_index, test_index in cv.split(x, y, groups):\n","    x_train_fold, x_test_fold = x_scaled[train_index], x_scaled[test_index]\n","    y_train_fold, y_test_fold = y[train_index], y[test_index]\n","    lr.fit(x_train_fold, y_train_fold)\n","    lst_accu_stratified.append(lr.score(x_test_fold, y_test_fold))\n","  \n","# Print the output.\n","print('List of possible accuracy:', lst_accu_stratified)\n","print('\\nMaximum Accuracy That can be obtained from this model is:',\n","      max(lst_accu_stratified)*100, '%')\n","print('\\nMinimum Accuracy:',\n","      min(lst_accu_stratified)*100, '%')\n","print('\\nOverall Accuracy:',\n","      mean(lst_accu_stratified)*100, '%')\n","print('\\nStandard Deviation is:', stdev(lst_accu_stratified))\n","\n","\n","\n","\n","for train_idxs, test_idxs in cv.split(X, y, groups):\n","    clf.fit(np.vstack(X[train_idxs]), y[train_idxs])\n","    print(clf.score(np.vstack(X[test_idxs]), y[test_idxs]))\n","    clf.fit(np.vstack(X[train_idxs]), y[train_idxs])\n","    y_pred = clf.predict(np.vstack(X[test_idxs]))\n","    print(\"Adjusted Balanced accuracy:\", metrics.balanced_accuracy_score(y[test_idxs], y_pred, adjusted=True))\n","    print(\"Balanced accuracy:\", metrics.balanced_accuracy_score(y[test_idxs], y_pred))\n"],"metadata":{"id":"Mn9N_Ef-3IOe"},"execution_count":null,"outputs":[]}]}